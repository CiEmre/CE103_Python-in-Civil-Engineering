{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CE 103- INTRODUCTION TO COMPUTERS and PROGRAMMING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _The topics of the week !_\n",
    "\n",
    "- PANDAS\n",
    "    - Data Structures in Pandas\n",
    "    - Data Manipulation\n",
    "    - Import/Export Data \n",
    "    - Time Series Analysis\n",
    "    - Visualization\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas (derived from the term \"Panel Dara\") stands for “Python Data Analysis Library”, which is most preferred and widely used library of Python. Its very helpful tool especially for Data Scientists and Analysts, and its built on top of the NumPy package just as SciPy does.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# DATA STRUCTURES\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## 1. Series(1D)\n",
    "\n",
    "A one-dimensional labeledarray which can be in integer, string, python object etc. format. The axis labels are referred as index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> s = pd.Series(data, index = index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greetings = pd.Series([1, 2, 3], index = ['Good Morning','Good Afternoon','Good Evening'])\n",
    "print(greetings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed = np.array([3,5,7,9,11,13,15])\n",
    "s = pd.Series(mixed)        # create a pandas series by using Numpy Array\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.itemsize    # number of bytes allocated to each item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greetings.shape  # gets shape of the series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greetings.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greetings.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greetings.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create series from list with missing data\n",
    "\n",
    "s1 = pd.Series([1,3,5,np.nan,9], index = ['a','b','c','d','e'])   \n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create series with random and range fucntions\n",
    "\n",
    "rows = np.random.rand(15)\n",
    "columns = np.arange(0,15)\n",
    "s = pd.Series(rows, columns)\n",
    "rows, columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing values from series\n",
    "s[:]\n",
    "s[0:5]\n",
    "s[-3:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create series from dictionary\n",
    "\n",
    "dictionary ={ \"LectureCodes\" : [\"GTU_CE103\",\"GTU_CE105\",\"GTU_CE247\"],  # create a dictionary to convert json object\n",
    "              \"Avg_StudentPerLecture\" : 75, \n",
    "              \"NumberOfClass\" : 12 \n",
    "            }\n",
    "s2 = pd.Series(dictionary)\n",
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append series\n",
    "\n",
    "s3 = s2.append(s)\n",
    "s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete item from series\n",
    "\n",
    "s3.drop('NumberOfClass', inplace = True)\n",
    "s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete item from series\n",
    "\n",
    "s3.drop(7, inplace = True)\n",
    "s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# operations with series\n",
    "\n",
    "a, b = np.array([3,5,7,9]),np.array([2,4,6,8])\n",
    "s1 = pd.Series(a) \n",
    "s2 = pd.Series(b)\n",
    "s1 , s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1.add(s2) # add series to each other\n",
    "s1.add(10) # add fix number to all values in the series\n",
    "s1.mul(s2) # multiply two series with each other\n",
    "s1.div(s2) # division of series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1.max()\n",
    "s2.mean()\n",
    "s1.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## 2. Dataframe (2D)\n",
    "\n",
    "It is a 2-dimensional labeled data structure with different types of columns. Dataframe is main object in pandas which used to represent data with rows and columns such as excel spreadsheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe \n",
    "\n",
    "df = pd.DataFrame()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe using list\n",
    "\n",
    "consump_df = pd.DataFrame(['monday','wednesday','friday', 'sunday']) \n",
    "consump_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add columns to an existing dataframe\n",
    "\n",
    "shop_lst = ['milk','bread','egg','newspaper']\n",
    "consump_df[1] = shop_lst\n",
    "consump_df[2] = [3, 2, 4, 8] \n",
    "consump_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign header information to each column\n",
    "\n",
    "consump_df.columns = ['Service Days', 'Cart List', 'Cost in $']\n",
    "consump_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call data with columns or raws\n",
    "\n",
    "consump_df.columns\n",
    "consump_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consump_df['Service Days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column by assigning a column that does not exist\n",
    "\n",
    "consump_df['Customer Name'] = ['Aylin','Hasan','Murat','Selin']\n",
    "consump_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete column from dataframe\n",
    "\n",
    "del consump_df['Cart List']\n",
    "consump_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colomn to raw switch\n",
    "\n",
    "consump_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data selection in dataframe usinf row label\n",
    "\n",
    "consump_df.loc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## 3. Indexing\n",
    "\n",
    "Indexing refers to select specifin rows and columns of data from a dataframe. It can handle different combination of row-column selection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_df = pd.DataFrame(np.random.randn(5, 4), index=None, columns=['Site A', 'Site B', 'Site C', 'Site D'])\n",
    "shift_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-index level\n",
    "\n",
    "s = pd.Series(np.random.rand(3), index = [['a','b','c'],[3,5,8]])\n",
    "s.index.names = ['name','number']\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s['a']  # select a row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.DataFrame(np.random.randn(6, 4), index=list('abcdef'), columns=list('ABCD'))\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.loc['e':, 'C':'D']  # select specific rows and columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# NaN vs Null \n",
    "\n",
    "NaN or None are not number, they meen missing/not available data. In databases _**pd.notnull()**_ or _**df.isnull()**_ are very usefull to detect missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1,3,5,np.nan,9],[np.nan,np.NaN,8,9,10])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.fillna(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.fillna('hello')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# IMPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv file from storage\n",
    "\n",
    "df_tuik = pd.read_csv('Data_Input/tuik.csv', sep = '|')  # read csc file with delimiter \"|\"\n",
    "df_tuik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tuik = df_tuik.rename(columns = {'Unnamed: 2':'YEAR'}) # change the column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tuik.loc[df_tuik['YEAR'] == 2011]  # indexing rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tuik_new = df_tuik.loc[(df_tuik['YEAR'] >= 2000) & (df_tuik['YEAR'] <= 2020)] # indexing\n",
    "df_tuik_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = df_tuik_new.dropna(axis='columns')  # delete columns with NaN values\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_csv('Data_Input/tuik_new.csv')  # write data_df to a new csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In order to write a data frame to an excel file you should import _**\"ExcelWriter\"**_ module, which you may need to install by using pip command.\n",
    "\n",
    "> pip install XlsxWriter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets write to excel file\n",
    "\n",
    "writer = pd.ExcelWriter('Data_Input/tuik.xlsx', engine='xlsxwriter')\n",
    "data_df.to_excel(writer, 'tuik_sheet')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read from excel file\n",
    "\n",
    "xl = pd.ExcelFile('Data_Input/tuik.xlsx')       # load spreadsheet\n",
    "df1 = xl.parse('tuik_sheet')                    # assign sheet to the dataframe\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Append new sheet to an existing excel file, we need to import (or even install) _**\"openpyxl\"**_ module because _**\"xlswriter\"**_ does not support append mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --user openpyxl\n",
    "import openpyxl\n",
    "\n",
    "df2 = pd.DataFrame({'Percentage': np.random.rand(20)})   # define a new dataframe\n",
    "\n",
    "with pd.ExcelWriter('Data_Input/tuik.xlsx', engine = 'openpyxl', mode = 'a') as f:\n",
    "    df2.to_excel(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# DATA MANIPULATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df = pd.read_excel('Data_Input/sales.xlsx')\n",
    "sales_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_df = sales_df.drop('Row ID', axis = 1)\n",
    "filt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.sort_values(by=['Sales'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.drop_duplicates('City')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.sort_values(by=['Ship Date'], ascending=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# TIME SERIES ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python library data types for date and time is 'datetime','time', 'calendar'; for Pandas its 'Timestamp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from matplotlib import dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.date_range('20200310', periods=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert string to datetime\n",
    "datetime.strptime('11/28/2005','%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_str = \"10 march, 2020\"\n",
    "datetime.strptime(date_str, \"%d %B, %Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Type :- ',type(now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "print('Hour: ', now.hour)\n",
    "print('Minute: ', now.minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now.weekday()  # gets the day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dealing with time zone\n",
    "\n",
    "from datetime import timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTC(Coordinated Universal Time) integer representing nanoseconds elapsed since midnight Thursday, January 1, 1970\n",
    "\n",
    "loc_time = datetime.utcnow()   \n",
    "loc_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce103_final = datetime.utcfromtimestamp(1591943043)   # defines nanoseconds from UTC to Final Exam date\n",
    "ce103_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar  # is also a helpful module to define date operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar.day_name[ce103_final.weekday()]  # find the weekday of given timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timespan and Time difference settlement\n",
    "\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get difference between two datetime objects\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "time_df = datetime(2020, 3, 10) + timedelta(60)  # adds 60 days to start time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timedelta(days = 130, hours = 21, minutes = 43) # gives day, seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DateTime objects in Pandas\n",
    "\n",
    "pd.to_datetime(\"26th of march, 2020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Timestamp(datetime(2020, 3, 26))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Timestamp('2005-11-28')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Timestamp(2012, 5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Period('2011-01') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Period('2012-05', freq='D')  # sets the frequency as Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set series with random dates\n",
    "\n",
    "pd.date_range('2005-10-18 20:02:55', periods=5, freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[datetime(2012, 5, 1), datetime(2012, 5, 2), datetime(2012, 5, 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime([2, 4, 30], unit='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime([10, 20, 30], unit='D', origin=pd.Timestamp('1900-01-01'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime([2903847.3, 38942081, 190283749.9828374], unit='s')  # unit \"s\" refers to seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime([2903847.3, 38942081, 190283749.9828374], unit='ns') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime(2020, 3, 10)\n",
    "end = datetime.now()\n",
    "pd.date_range(start, end) # default frequency for date_range is a calendar day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.bdate_range(start, end, freq='B')  # the default for bdate_range is a business day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _**Timestamp Limitations**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Timestamp.min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Timestamp.max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shipping_df = sales_df.drop_duplicates('Ship Date')\n",
    "shipping_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "shipping_df['Quantity'].hist(bins=10)\n",
    "plt.xlabel('Quantity')\n",
    "plt.ylabel('Number of Data')\n",
    "labels = [\"Quantity\"]\n",
    "plt.legend(labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 8))\n",
    "df_x = shipping_df['Ship Date'].tolist()\n",
    "df_y = shipping_df['Sales'].tolist()\n",
    "plt.bar(df_x,df_y, width=5, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets define time random series with date index\n",
    "\n",
    "ts = pd.Series(np.random.randn(1000), index=pd.date_range('1/1/2000', periods=1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets define a random time series and visualize it\n",
    "\n",
    "lockdown_df = pd.DataFrame(np.random.randn(1000,1)*np.sin(30), columns=['BrainCell'], index=pd.date_range('2020-03-10', periods = 1000, freq='T'))\n",
    "df = lockdown_df.cumsum()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize=(15, 8) )\n",
    "plt.plot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Homework #10\n",
    "\n",
    "Please follow the instructions below. \n",
    "\n",
    "1 - Visit the following web page and import dataset in excel format. https://data.ibb.gov.tr/dataset/ulasim-yonetim-merkezi-uym-tarafindan-sisteme-girilen-trafik-duyurulari/resource/02bfe245-5e5a-472b-b0a4-323d1bae8131\n",
    "\n",
    "![](./Figures/homework10.png)\n",
    "\n",
    "2 - Read the columns from the excel file (\"UYM Duyurular\" Sheet), classify them belongs to \"Duyuru Tipi\" column and draw histogram plot.\n",
    "\n",
    "3 - Create new sheet in the same excel file named as \"output\" and write \"Duyuru ID\", \"Duyuru Tipi\", \"Müdahale Tarihi\" and \"Koordinatlar\" (seperate into two columns as \"Enlem\" and \"Boylam\") for only values labeled as \"Kaza Bildirimi\". Read these columns and plot a figure for Time vs Kaza Bildirimi.  \n",
    "\n",
    "4 - Compute the time differernce between \"Giriş Tarihi\" and \"Müdahale Tarihi\" and calculate average time of intervene time per event. \n",
    "\n",
    "\n",
    "*** Be carefull about \"NaN or Null values\" in your data, they may disrupt your calculations.\n",
    "\n",
    "PS : Do not forget to upload your answer sheets to CE_103 Class on MS Teams.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
